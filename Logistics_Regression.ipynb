{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assginment 2: Supervised Learning: Regression Models and Performance Metrics**"
      ],
      "metadata": {
        "id": "9VIryfMBzGMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
        "\n",
        "\n",
        ">Simple Linear Regression (SLR) is a statistical method used to model the relationship between two variables — one independent variable (X) and one dependent variable (Y) — by fitting a straight line through the data points.\n",
        "\n",
        ">**Equation of Simple Linear Regression**\n",
        "\n",
        " >>Y=β₀​+β₁​X+ε\n",
        "\n",
        ">Where:\n",
        "\n",
        ">>Y = Dependent variable (the one we want to predict)\n",
        "\n",
        ">>X = Independent variable (the predictor)\n",
        "\n",
        ">>β₀ = Intercept (value of Y when X = 0)\n",
        "\n",
        ">>β₁ = Slope (change in Y for each unit change in X)\n",
        "\n",
        ">>ε = Error term (difference between actual and predicted values)\n",
        "\n",
        ">**Purpose of Simple Linear Regression**\n",
        "\n",
        ">1.Prediction:\n",
        ">>To predict the value of a dependent variable based on the value of an independent variable.\n",
        "\n",
        ">>Example: Predicting a student’s exam score (Y) based on study hours (X).\n",
        "\n",
        ">2.Relationship Identification:\n",
        ">>To determine whether and how strongly two variables are linearly related.\n",
        "\n",
        ">>Example: Checking if sales increase with advertisement spending.\n",
        "\n",
        ">3.Trend Analysis:\n",
        ">>To understand trends and make future forecasts from past data.\n",
        "\n",
        ">4.Quantification of Impact:\n",
        ">>To measure how much change in the independent variable affects the dependent variable.\n",
        "\n",
        ">**Example**\n",
        "\n",
        ">>Suppose we have data on hours studied (X) and marks scored (Y):\n",
        "\n",
        "| Hours Studied (X) | Marks (Y) |\n",
        "| ----------------- | --------- |\n",
        "| 2                 | 50        |\n",
        "| 4                 | 60        |\n",
        "| 6                 | 70        |\n",
        "| 8                 | 80        |\n",
        "\n",
        "\n",
        "\n",
        ">>This means:\n",
        "\n",
        ">>The intercept (40) is the expected marks if no hours are studied.\n",
        "\n",
        ">>The slope (5) means for every extra hour studied, marks increase by 5 points."
      ],
      "metadata": {
        "id": "76Km5gQcy-MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        ">The **key assumptions of Simple Linear Regression (SLR)** ensure that the model is valid and the predictions are reliable.\n",
        "\n",
        "\n",
        " >**1. Linearity**\n",
        "\n",
        ">* The relationship between the **independent variable (X)** and the **dependent variable (Y)** is **linear**.\n",
        ">* This means that a change in X results in a proportional change in Y.\n",
        "  >> *Example:* If hours studied double, marks should roughly double.\n",
        "\n",
        " >>**Check:** Use scatter plots of X vs Y — the points should form a roughly straight-line pattern.\n",
        "\n",
        "\n",
        "\n",
        "> **2. Independence of Errors**\n",
        "\n",
        ">* The residuals (errors) should be **independent** of each other.\n",
        ">* There should be **no autocorrelation** (i.e., one error should not depend on another).\n",
        "\n",
        " >>**Check:** Use the **Durbin–Watson test** to detect autocorrelation.\n",
        "\n",
        "\n",
        "\n",
        ">**3. Homoscedasticity (Constant Variance)**\n",
        "\n",
        ">* The variance of the residuals (errors) should be **constant** across all levels of X.\n",
        ">* That is, the spread of errors should be roughly the same for all predicted values.\n",
        "\n",
        " >>>If the spread increases or decreases with X, it indicates **heteroscedasticity**.\n",
        "\n",
        " >>**Check:** Plot residuals vs fitted values — the points should be randomly scattered without a funnel shape.\n",
        "\n",
        "\n",
        ">**4. Normality of Errors**\n",
        "\n",
        ">* The residuals (errors) should follow a **normal distribution**.\n",
        ">* This is important for accurate hypothesis testing and confidence intervals.\n",
        "\n",
        ">> **Check:** Use a **Q-Q plot** or **histogram of residuals** — they should look approximately normal.\n",
        "\n",
        ">**5. No Multicollinearity (Not applicable for SLR)**\n",
        "\n",
        ">* Since SLR has only **one independent variable**, this assumption applies only to **multiple regression**.\n",
        ">* But still, X should not be a constant or perfectly correlated with any other variable.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xLg6p8WEzL-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.**Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.**\n",
        "\n",
        "\n",
        ">The **mathematical equation** for a **Simple Linear Regression (SLR)** model is:\n",
        "\n",
        ">>Y = β₀ + β₁X + ε\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ">**Explanation of Each Term**\n",
        "\n",
        "| **Term**           | **Name**                        | **Meaning / Role**                                                                                                                                |\n",
        "| ------------------ | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Y**              | Dependent Variable              | The variable we want to **predict or explain**. <br>Example: Marks scored, house price, etc.                                                      |\n",
        "| **X**              | Independent Variable            | The variable used to **predict Y**. <br>Example: Hours studied, area of the house, etc.                                                           |\n",
        "| **β₀ (Beta-zero)** | Intercept                       | The **value of Y when X = 0**. <br>It represents the baseline or starting value.                                                                  |\n",
        "| **β₁ (Beta-one)**  | Slope or Regression Coefficient | Shows how much **Y changes** for a **one-unit increase in X**. <br>If β₁ = 5, then for every 1 increase in X, Y increases by 5 units.             |\n",
        "| **ε (Epsilon)**    | Error Term or Residual          | Represents the **difference** between the **actual** and **predicted** Y values. <br>It captures randomness or factors not included in the model. |\n",
        "\n",
        "\n",
        ">**Example**\n",
        "\n",
        ">Suppose we are predicting **marks (Y)** based on **hours studied (X)**:\n",
        "\n",
        ">>Y = 40 + 5X + ε\n",
        "\n",
        "\n",
        ">Here:\n",
        "\n",
        ">* **β₀ = 40** → Base marks if no hours are studied.\n",
        ">* **β₁ = 5** → For every extra hour studied, marks increase by 5.\n",
        ">* **ε** → Random error due to factors like mood, environment, or luck.\n"
      ],
      "metadata": {
        "id": "41pR3f_5zR81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.**Provide a real-world example where simple linear regression can be\n",
        "applied.**\n",
        "\n",
        "\n",
        "> **Real-World Example: Predicting House Prices**\n",
        "\n",
        ">>**Scenario:**\n",
        "A real estate company wants to **predict the price of a house (Y)** based on its **size in square feet (X)**.\n",
        "\n",
        "\n",
        "\n",
        ">>**Application of Simple Linear Regression**\n",
        "\n",
        ">>We collect past data like this:\n",
        "\n",
        "| House Size (sq. ft) (X) | Price (₹ Lakhs) (Y) |\n",
        "| ----------------------- | ------------------- |\n",
        "| 800                     | 40                  |\n",
        "| 1000                    | 50                  |\n",
        "| 1200                    | 60                  |\n",
        "| 1500                    | 75                  |\n",
        "| 1800                    | 90                  |\n",
        "\n",
        ">>The regression analysis gives the equation:\n",
        "\n",
        ">>>Y = 10 + 0.045X\n",
        "\n",
        "\n",
        ">> **Interpretation:**\n",
        "\n",
        ">>* **β₀ = 10** → A house with 0 sq. ft (theoretically) costs ₹10 lakhs (base cost such as land, location, etc.).\n",
        ">>* **β₁ = 0.045** → For every **1 sq. ft increase in area**, the **price increases by ₹0.045 lakhs (₹4,500)**.\n",
        "\n",
        "\n",
        "\n",
        ">> **Use:**\n",
        "\n",
        ">>If a customer wants to know the estimated price of a **1600 sq. ft house**:\n",
        "\n",
        ">>Y = 10 + 0.045(1600) = 82 \\text{ lakhs}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v7AwGqfazfjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.**What is the method of least squares in linear regression?**\n",
        "\n",
        ">The **Method of Least Squares** is a **mathematical approach** used in **linear regression** to find the **best-fitting line** through a set of data points by **minimizing the sum of the squared errors (residuals)**.\n",
        "\n",
        "\n",
        ">**Concept** :\n",
        "\n",
        ">>In **Simple Linear Regression**, the equation of the line is:\n",
        "\n",
        ">>>Y = β_0 + β_1X + ε\n",
        "\n",
        ">>But the actual data points ((X_i, Y_i)) will not all lie exactly on this line — there will be **errors** (differences) between the **actual values (Yᵢ)** and the **predicted values (Ŷᵢ)**.\n",
        "\n",
        ">>These differences are called **residuals**:\n",
        "\n",
        ">>>e_i = Y_i - Ŷ_i\n",
        "\n",
        ">**Goal of Least Squares**\n",
        "\n",
        ">>The goal is to choose values of **β₀** and **β₁** that **minimize the sum of squared residuals (errors)**:\n",
        "\n",
        ">>>\\text{Minimize } S = \\sum (Y_i - Ŷ_i)^2 = \\sum (Y_i - (β_0 + β_1X_i))^2\n",
        "\n",
        "\n",
        ">>This ensures the regression line is the one that fits the data **as closely as possible**.\n",
        "\n",
        "> **Formulas for Coefficients**\n",
        "\n",
        ">>By solving the minimization equations, we get:\n",
        "\n",
        ">>>β1​=∑(Xi​−Xˉ)(Yi​−Yˉ)/2∑(Xi​−Xˉ)^2\n",
        "\n",
        ">>>β0​=Yˉ−β1​Xˉ\n",
        "\n",
        ">>Where:\n",
        "\n",
        ">>* (Xˉ) = Mean of X values\n",
        ">>* (Yˉ) = Mean of Y values\n",
        "\n",
        "> **Intuitive Understanding**\n",
        "\n",
        ">>* “Least Squares” means we’re **making the total squared distance** between actual and predicted Y values **as small as possible**.\n",
        ">>* Squaring ensures that positive and negative errors don’t cancel out and gives more weight to larger errors.\n",
        "\n",
        "\n",
        ">**Example**\n",
        "\n",
        "| X (Hours studied) | Y (Marks) | Predicted Ŷ | Residual (Y–Ŷ) | (Y–Ŷ)² |\n",
        "| ----------------- | --------- | ----------- | -------------- | ------ |\n",
        "| 2                 | 50        | 52          | -2             | 4      |\n",
        "| 4                 | 60        | 61          | -1             | 1      |\n",
        "| 6                 | 70        | 70          | 0              | 0      |\n",
        "| 8                 | 80        | 79          | 1              | 1      |\n",
        "\n",
        ">The **least squares line** minimizes the total of the last column → **∑(Y–Ŷ)² = 6** (minimum possible).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ygrkwA_MzhD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.**What is Logistic Regression? How does it differ from Linear Regression?**\n",
        "\n",
        "> **Logistic Regression**\n",
        "\n",
        ">>**Logistic Regression** is a **supervised machine learning algorithm** used for **classification problems**, where the **dependent variable (Y)** is **categorical** — usually **binary (0 or 1)**.\n",
        "\n",
        ">>It predicts the **probability** that an observation belongs to a particular class (e.g., “Yes” or “No”, “Spam” or “Not Spam”).\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        ">**Mathematical Form**\n",
        "\n",
        ">>Unlike Linear Regression, which predicts a continuous value, Logistic Regression predicts a **probability (p)** using the **sigmoid (logistic) function**:\n",
        "\n",
        "\n",
        ">>>p = \\frac{1}{1 + e^{-(β_0 + β_1X)}}\n",
        "\n",
        "\n",
        ">>Where:\n",
        "\n",
        ">>* **p** = Probability that Y = 1\n",
        ">>* **β₀, β₁** = Model coefficients\n",
        ">>* **e** = Exponential constant (~2.718)\n",
        "\n",
        ">The predicted probability (p) is always between **0 and 1**.\n",
        "To classify, we set a **threshold** (usually 0.5):\n",
        "\n",
        ">>* If (p ≥ 0.5), predict **1** (Yes/True)\n",
        ">>* If (p < 0.5), predict **0** (No/False)\n",
        "\n",
        "<br>\n",
        "\n",
        ">**Purpose**\n",
        "\n",
        ">>To model the **relationship between input variables (X)** and the **probability of an event occurring (Y=1)**.\n",
        "\n",
        ">> Example: Predict whether a student will pass (1) or fail (0) based on study hours.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "> **Difference Between Linear and Logistic Regression**\n",
        "\n",
        "| **Aspect**               | **Linear Regression**                          | **Logistic Regression**                                              |\n",
        "| ------------------------ | ---------------------------------------------- | -------------------------------------------------------------------- |\n",
        "| **Purpose**              | Predicts a **continuous** value                | Predicts a **categorical** outcome (usually binary)                  |\n",
        "| **Output Range**         | Output can be **any real number** (−∞ to +∞)   | Output is a **probability between 0 and 1**                          |\n",
        "| **Equation**             | (Y = β_0 + β_1X)                               | (p = \\frac{1}{1 + e^{-(β_0 + β_1X)}})                                |\n",
        "| **Type of Relationship** | Models **linear** relationship between X and Y | Models **non-linear** relationship using **sigmoid curve**           |\n",
        "| **Use Case Example**     | Predicting house prices, sales, temperature    | Predicting if a customer will buy (Yes/No), disease (Present/Absent) |\n",
        "| **Error Function Used**  | Mean Squared Error (MSE)                       | Log Loss (Cross-Entropy)                                             |\n",
        "| **Nature of Model**      | Regression (continuous output)                 | Classification (discrete output)                                     |\n",
        "\n",
        "<br>\n",
        "\n",
        ">**Graphical View**\n",
        "\n",
        ">* **Linear Regression:** Produces a **straight line** prediction\n",
        ">* **Logistic Regression:** Produces an **S-shaped (sigmoid) curve**\n",
        "\n"
      ],
      "metadata": {
        "id": "V2EdmTSaznzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.**Name and briefly describe three common evaluation metrics for regression\n",
        "models.**\n",
        "\n",
        ">**Three common evaluation metrics** used to assess the performance of **regression models**\n",
        "\n",
        "<br>\n",
        "\n",
        ">**1. Mean Absolute Error (MAE)**\n",
        "\n",
        ">>MAE = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - Ŷ_i|\n",
        "\n",
        "\n",
        ">**Description:**\n",
        "\n",
        ">* MAE measures the **average absolute difference** between the actual values (**Yᵢ**) and the predicted values (**Ŷᵢ**).\n",
        ">* It gives an idea of how **far predictions are from actual values**, on average.\n",
        ">* It treats all errors **equally**, regardless of direction.\n",
        "\n",
        ">**Interpretation:**\n",
        "\n",
        ">* Lower MAE → Better model performance.\n",
        ">* Example: MAE = 3 means, on average, predictions are off by 3 units.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **2. Mean Squared Error (MSE)**\n",
        "\n",
        "\n",
        ">>MSE = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - Ŷ_i)^2\n",
        "\n",
        "\n",
        ">**Description:**\n",
        "\n",
        ">* MSE measures the **average of the squared differences** between actual and predicted values.\n",
        ">* It gives **more weight to large errors**, because errors are **squared**.\n",
        ">* It’s useful when **large errors are particularly undesirable**.\n",
        "\n",
        "> **Interpretation:**\n",
        "\n",
        ">* Smaller MSE = More accurate model.\n",
        ">* Sensitive to outliers due to squaring.\n",
        "\n",
        "<br>\n",
        "\n",
        ">**3. R-squared (Coefficient of Determination)**\n",
        "\n",
        ">>R²= 1− ( ∑(Yi​−Yˉ)^2  / ∑(Yi​−Y^i​)^2 )\n",
        "\n",
        ">**Description:**\n",
        "\n",
        ">* R² measures how well the regression line **explains the variability** in the dependent variable (Y).\n",
        ">* It represents the **proportion of variance** in Y that is explained by X.\n",
        "\n",
        " >**Interpretation:**\n",
        "\n",
        ">* R² ranges from **0 to 1**\n",
        "\n",
        "  >* **0** → Model explains none of the variability\n",
        "  >* **1** → Model perfectly explains all variability\n",
        ">* Example: R² = 0.85 → 85% of the variation in Y is explained by X.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mL0qmIfVzpY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.**What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        "> **Purpose of R-squared Metric in Regression Analysis**\n",
        "\n",
        ">>**R-squared (R²)**, also known as the **coefficient of determination**, measures how well the **regression model explains the variability** of the dependent variable (**Y**) based on the independent variable(s) (**X**).\n",
        "\n",
        ">>R²= 1− ( ∑(Yi​−Yˉ)^2  / ∑(Yi​−Y^i​)^2 )\n",
        "<br>\n",
        "\n",
        "> **Key Points**\n",
        "\n",
        ">* **R² value ranges from 0 to 1:**\n",
        "\n",
        "  >>* **0** → Model explains none of the variation in Y.\n",
        "  >>* **1** → Model perfectly explains all the variation in Y.\n",
        ">* It represents the **proportion of variance** in the dependent variable that is **explained by the independent variable(s)**.\n",
        ">* Higher **R²** indicates a **better model fit**.\n",
        "\n",
        "<br>\n",
        "\n",
        ">  **Example**\n",
        "\n",
        ">>If a regression model has **R² = 0.85**, it means:\n",
        "\n",
        ">>>85% of the variation in the dependent variable is explained by the model, and the remaining 15% is due to other unexplained factors (errors or noise).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k0iEEBuRztnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''9.Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.'''\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "# X = independent variable (reshape required for sklearn)\n",
        "# Y = dependent variable\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Print the slope (coefficient) and intercept\n",
        "print(\"Slope (β₁):\", model.coef_[0])\n",
        "print(\"Intercept (β₀):\", model.intercept_)\n",
        "\n",
        "# Optional: print predicted values\n",
        "Y_pred = model.predict(X)\n",
        "print(\"\\nPredicted values:\", Y_pred)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "753cU2biz2RH",
        "outputId": "a17db9fd-ebeb-41fd-aaf4-4172536c7107"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (β₁): 0.6\n",
            "Intercept (β₀): 2.2\n",
            "\n",
            "Predicted values: [2.8 3.4 4.  4.6 5.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.How do you interpret the coefficients in a simple linear regression model?**\n",
        "\n",
        "> **Interpretation of Coefficients in a Simple Linear Regression Model**\n",
        "\n",
        ">>A **Simple Linear Regression** model is represented as:\n",
        "\n",
        "\n",
        ">>>Y = β₀ + β₁X + ε\n",
        "\n",
        "\n",
        ">>Where:\n",
        "\n",
        ">>* **Y** → Dependent (response) variable\n",
        ">>* **X** → Independent (predictor) variable\n",
        ">>* **β₀** → Intercept\n",
        ">>* **β₁** → Slope (coefficient of X)\n",
        ">>* **ε** → Error term\n",
        "\n",
        "\n",
        "> **1. Intercept (β₀)**\n",
        "\n",
        ">* It represents the **predicted value of Y when X = 0**.\n",
        ">* In other words, it is the **starting point** or **baseline value** of the dependent variable.\n",
        "\n",
        ">> Example: If β₀ = 40, it means when X = 0, Y is expected to be 40.\n",
        "\n",
        "\n",
        "> **2. Slope (β₁)**\n",
        "\n",
        ">* It represents the **change in Y** for a **one-unit increase in X**.\n",
        ">* It shows the **strength and direction** of the relationship between X and Y:\n",
        "\n",
        "  >>* If **β₁ > 0**, Y increases as X increases.\n",
        "  >>* If **β₁ < 0**, Y decreases as X increases.\n",
        "\n",
        ">> Example: If β₁ = 5, then for every additional unit increase in X, Y increases by 5 units (on average).\n",
        "\n",
        "\n",
        "> **Example**\n",
        "\n",
        ">>If the fitted model is:\n",
        "\n",
        ">>>Y = 40 + 5X\n",
        "\n",
        "\n",
        ">>* **β₀ = 40** → When X = 0, predicted Y = 40.\n",
        ">>* **β₁ = 5** → For each 1-unit increase in X, Y increases by 5.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WIDrcH7o0F6-"
      }
    }
  ]
}